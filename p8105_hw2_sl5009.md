p8105\_hw2\_sl5009
================
Shengzhi Luo
08/10/2021

``` r
library(tidyverse)
library(readxl)
library(dplyr)
library(ggridges)
```

## Prolem 1

Read and clean the Mr.Trash Wheel sheet.

``` r
Mr_Trash_Wheel<-read_excel("./Trash-Wheel-Collection-Totals-7-2020-2.xlsx")
Mr_Trash_Wheel=janitor::clean_names(Mr_Trash_Wheel)
```

Omit rows that do not include dumpster-specific data.

``` r
Mr_Trash_Wheel=drop_na(Mr_Trash_Wheel,dumpster)
```

Round the number of sports balls to the nearest integer.

``` r
Mr_Trash_Wheel$sports_balls=round(Mr_Trash_Wheel$sports_balls,digits = 0)
```

Read and clean precipitation data for 2018 and 2019.

``` r
Pre_2018=
  read_excel("./Trash-Wheel-Collection-Totals-7-2020-2.xlsx",sheet="2018 Precipitation")%>%
  janitor::clean_names()%>%
  drop_na()%>%
  mutate(
    year=2018
    )
Pre_2018=Pre_2018[-1,]
```

``` r
Pre_2019=
  read_excel("./Trash-Wheel-Collection-Totals-7-2020-2.xlsx",sheet="2019 Precipitation")%>%
  janitor::clean_names()%>%
  drop_na()%>%
  mutate(year=2019)
Pre_2019=Pre_2019[-1,]
```

Combine precipitation datasets and convert month to a character
variable.

``` r
Pre_2018_2019=
  bind_rows(Pre_2018,Pre_2019) %>%
  mutate(
    precipitation_in=month.name[as.numeric(precipitation_in)]
  )
Pre_2018_2019
```

    ## # A tibble: 24 × 3
    ##    precipitation_in x2                  year
    ##    <chr>            <chr>              <dbl>
    ##  1 January          0.94                2018
    ##  2 February         4.8                 2018
    ##  3 March            2.69                2018
    ##  4 April            4.6900000000000004  2018
    ##  5 May              9.27                2018
    ##  6 June             4.7699999999999996  2018
    ##  7 July             10.199999999999999  2018
    ##  8 August           6.45                2018
    ##  9 September        10.47               2018
    ## 10 October          2.12                2018
    ## # … with 14 more rows

``` r
Pre_2018_sum=sum(as.numeric(Pre_2018$x2))
```

``` r
Mr_Trash_Wheel_2019=filter(Mr_Trash_Wheel,year=="2019")
Mr_Trash_Wheel_median=median(Mr_Trash_Wheel_2019$sports_balls)
```

The precipitation data on May, July and September of 2018 are very rainy
than the rest of the time of 2018 while data on 2019 are relatively low
comparing to 2018 throughout the whole year of 2019. The total
precipitation in 2018 is 70.33 and the median number of sports balls in
a dumpster in 2019 is 9.

## Problem 2

Clean the data in pols-month.csv.

``` r
pols_month=
  read.csv("./fivethirtyeight_datasets/pols-month.csv")%>%
  separate(mon,into=c("year","month","day"))%>%
  mutate(
    president=prez_gop+prez_dem,
    month = month.abb[as.numeric(month)],
    year=as.numeric(year))%>%
  select(-c("prez_gop","prez_dem","day"))
```

Clean the data in snp.csv.

``` r
snp=
  read.csv("./fivethirtyeight_datasets/snp.csv")%>%
  separate(date,into=c("month","day","year"))%>%
  arrange(as.numeric(month))%>%
  mutate(
    month = month.abb[as.numeric(month)]
    )%>%
  select(-c("day"))%>%
  relocate(year,month,close)%>%
  mutate(
    year=as.numeric(year),
    year=ifelse(year>47, 1900+year, 2000+year)
  )%>%
  arrange(year)
```

Tidy the unemployment data so that it can be merged with the previous
datasets.

``` r
unemployment=
  read.csv("./fivethirtyeight_datasets/unemployment.csv")%>%
  pivot_longer(
    Jan:Dec,
    names_to="month",
    values_to = "unemployment rate"
  )
colnames(unemployment) <- c("year","month","unemployment rate")
```

Join the datasets by merging snp into pols, and merging unemployment
into the result.

``` r
fas_data=
  left_join(pols_month,snp,by=c("year","month"))
res_data=
  left_join(fas_data,unemployment,by=c("year","month"))
```

The pols\_month dataset contained 822 observations of 9 variables
related to the number of national politicians who are democratic or
republican at any given time as governors, senators, representatives and
president. The snp dataset contained tandard & Poor’s stock market index
(S&P), often used as a representative measure of stock market as a whole
with the closing values of the S&P stock index on each months from
1950-2015. The unemployment dataset contained percentage of unemployment
in each months from 1948-2015.

## Problem 3

Load and tidy the data.

``` r
Popular_Baby_Names=
  read.csv("./Popular_Baby_Names.csv")%>%
  janitor::clean_names() %>%
  mutate(child_s_first_name=stringr::str_to_title(child_s_first_name))%>%
  mutate(ethnicity=replace(ethnicity,ethnicity=="ASIAN AND PACI","ASIAN AND PACIFIC ISLANDER"),
         ethnicity=replace(ethnicity,ethnicity=="BLACK NON HISP","BLACK NON HISPANIC"),
         ethnicity=replace(ethnicity,ethnicity=="WHITE NON HISP","WHITE NON HISPANIC")
         )
Popular_Baby_Names=distinct(Popular_Baby_Names)
```

Produce a well-structured, reader-friendly table showing the rank in
popularity of the name “Olivia” as a female baby name over time.

``` r
Olivia_rank=
  filter(Popular_Baby_Names, child_s_first_name=="Olivia")%>%
  pivot_wider(
  names_from = "year_of_birth", 
  values_from = c(count,rank)
  )%>%
  relocate(child_s_first_name,ethnicity)
```

Produce a table showing the most popular name among male children over
time.

``` r
male_rank=
  filter(Popular_Baby_Names, gender=="MALE")%>%
  filter(rank==1)%>%
  pivot_wider(
  names_from = "year_of_birth", 
  values_from = c(count,rank)
  )
```

Produce a scatter plot showing the number of children with a name (y
axis) against the rank in popularity of that name (x axis).

``` r
male_white_2016=
  filter(Popular_Baby_Names,gender=="MALE",ethnicity=="WHITE NON HISPANIC",year_of_birth=="2016")
male_white_2016%>%
  ggplot(aes(x=rank,y=count))+
  geom_point()
```

![](p8105_hw2_sl5009_files/figure-gfm/unnamed-chunk-17-1.png)<!-- -->
